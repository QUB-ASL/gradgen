import opengen as og
import casadi.casadi as cs
import matplotlib.pyplot as plt
import numpy as np
import gradgen

# stochastic inverted pendulum example
# code generated by gradgen and open

# tree
p = np.array([[0.2, 0.3, 0.5],
              [0.1, 0.25, 0.65],
              [0.05, 0.8, 0.15]])
v_tree = np.array([0.6, 0.1, 0.3])
N = 10
tau = 4
tree = gradgen.MarkovChainScenarioTreeFactory(p, v_tree, N, tau).create()
num_events = tree.num_possible_events()
print(tree)

# system parameters
nx = 2
nu = 1
M = 3
m = 1
L = 0.35
g = 9.81
Mtot = M + m

# cost parameters
q_theta = 1
q_theta_dot = 0.2
r = 1


def f(x_, u_, t_sampling_):
    return gradgen.ModelFactory.create_inv_pend_model(x_, u_, m=m, ell=L, M=M, g=g, t_sampling=t_sampling_)


def ell(x_, u_):
    return q_theta * x_[0]**2 + q_theta_dot * x_[1]**2 + r * u_**2


def vf(x_):
    return 0.5 * cs.dot(x_, x_)


def t_s_at_event(event_):
    return 0.01 * (1 + 0.5 * event_)


# ---- gradgen ----

x = cs.SX.sym('x', nx)  # state
u = cs.SX.sym('u', nu)  # input

# list of f and ell for each event
f_of_, ell_of_ = [None] * num_events, [None] * num_events
for event in range(num_events):
    t_s_of_current_event = t_s_at_event(event)
    f_of_[event] = f(x, u, t_s_of_current_event)
    ell_of_[event] = ell(x, u)

v_terminal = vf(x)

# generate code with gradgen
gradiator = gradgen.CostGradientStochastic(tree, x, u, f_of_, ell_of_, v_terminal)
gradiator.with_target_path("./generated_code").with_name("bm_algo_2_inv_pend_gradgen").build()


# ---- open ----

u = cs.SX.sym('u', nu * tree.num_nonleaf_nodes)  # sequence of inputs
z0 = cs.SX.sym('z0', nx)  # initial state

cost = ell(z0, u[0])  # root node cost
z_seq = [None] * tree.num_nonleaf_nodes  # sequence of states
z_seq[0] = z0

for i in range(1, tree.num_nonleaf_nodes):  # looping through all non-leaf nodes
    idx_anc = tree.ancestor_of(i)
    prob_i = tree.probability_of_node(i)

    x_anc = z_seq[idx_anc]
    u_anc = u[idx_anc * nu: (idx_anc+1) * nu]
    u_current = u[i * nu: (i+1) * nu]
    t_s_current = t_s_at_event(tree.event_at_node(i))

    x_current = f(x_anc, u_anc, t_s_current)
    cost += tree.probability_of_node(i) * ell(x_current, u_current)
    z_seq[i] = cs.vertcat(x_current)

    if tree.stage_of(i) == N - 2:
        for i_plus in tree.children_of(i):
            t_s_current = t_s_at_event(tree.event_at_node(i_plus))
            x_plus = f(x_anc, u_anc, t_s_current)
            cost += tree.probability_of_node(i_plus) * vf(x_plus)

# generate casadi code via open
#
# this will generate C code at:
#   __name__/icasadi___name__/extern/auto_casadi_grad.c
# and a Rust wrapper at:
#   __name__/icasadi___name__/
# look at:
#   __name__/icasadi___name__/src/lib.rs
# there you will find the function:
#   pub fn grad(u: &[f64], xi: &[f64], static_params: &[f64], cost_jacobian: &mut [f64]) -> i32
# look at the test function tst_call_grad (line 303) to see how to use it.
bounds = og.constraints.NoConstraints()
problem = og.builder.Problem(u, z0, cost)\
    .with_constraints(bounds)
build_config = og.config.BuildConfiguration()\
    .with_build_directory("./generated_code")
meta = og.config.OptimizerMeta().with_optimizer_name("bm_algo_2_inv_pend_open")
solver_config = og.config.SolverConfiguration()
builder = og.builder.OpEnOptimizerBuilder(problem,
                                          meta,
                                          build_config,
                                          solver_config).with_generate_not_build_flag(True)
builder.build()
